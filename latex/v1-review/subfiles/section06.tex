\documentclass[main.tex]{subfiles}

\begin{document}
    \justifying

    \section{Conclusions}
    \label{section:conclusions} 

        The CLOUDSC and CLOUDSC2 cloud microphysics schemes of the IFS at ECMWF have served as demonstrators to show the benefits of a high-level domain-specific implementation approach to physical parametrizations. We presented two Python implementations based on the GT4Py framework, in which the scientific code is insulated from hardware-specific aspects. The resulting application provides a productive user interface with enhanced readability and maintainability, and can run efficiently and in a very robust manner across a wide spectrum of compute architectures/systems. The approach can be powerful in the light of the increasingly complex HPC technology landscape, where general-purpose CPUs are increasingly complemented by domain-specific architectures (DSAs) such as GPUs, Tensor Processor Units (TPUs), Field Programmable Gate Arrays (FPGAs), and Application-Specific Integrated Circuits (ASICS). In addition to the CLOUDSC scheme used in the IFS forecast model, we have presented results with the GT4Py rewrites of the nonlinear, tangent-linear and adjoint formulations of CLOUDSC2 used in data assimilation. 
    
        In both CLOUDSC-GT4Py and CLOUDSC2-GT4Py, the stencil kernels are encapsulated within model components sharing a minimal and clear interface. By avoiding any assumption on the host model, the interface aims to provide interoperable and plug-and-play physical packages, which can be transferred more easily between different modeling systems with virtually no performance penalty.
        
        We carried out a comprehensive study to assess the portability of the Python codes across three major supercomputers, differing in terms of the vendor, the node architecture, the software stack and the compiler suites. We showed that the GPU performance of GT4Py codes are competitive against optimized Fortran OpenACC implementations and perform particularly well when compared to the available codes generated with the Loki source-to-source translation tool. Low-level implementations written either in Fortran for CPUs or CUDA/HIP for GPUs, with additional optimizations that possibly require knowledge about the specific compute patterns, can provide better performance, but are extremely challenging to create and maintain for entire models. The CPU performance of GT4Py is currently suboptimal, but this is an expected result given the focus on GPUs in the DSL development so far and we clearly expect this to improve significantly with upcoming and future GT4Py versions. \review{Indeed, since the DSL can accommodate any specific low-level optimization, attaining the same performance as native Fortran and CUDA/HIP models is feasible and will be the target of our future efforts.}
        
        The presented results, based on a representative physical parametrization and considering tangent-linear and adjoint versions, add to the notion that weather and climate model codes can execute significantly faster on GPUs \citep{fuhrer18}, and the number of HPC systems with accelerators is steadily increasing\footnote{In the 62\textsuperscript{nd} edition of the TOP500 list published in November 2023, 186 out of the 500 most powerful supercomputers in the world use graphics accelerator technology (\url{https://www.top500.org/lists/top500/2023/11/highs/}).}. Therefore, we envision that CPUs will be increasingly relegated to tasks that are not time-critical.
    
        % On the other hand, we recognize that GPU performance are of utter importance in view of a future adoption of GT4Py in an operational context. We believe that the GPU porting of a full-fledged model via a ground-up rewriting using a DSL is not only possible, but also more sustainable and cost-effective than a directive-based approach. Indeed, DSLs enable a separation of concerns between domain scientists and computer experts, so that both can better exploit the respective field of expertise and thus boost their productivity. Notwithstanding, we stress that the development and maintenance of the DSL toolchain with respect to emerging computational patterns and heterogeneous compute platforms is complex and does not come for free. However, provided that the design of the toolchain is driven by a close synergy between domain scientists and computer experts, the advantages for all downstream applications significantly offset the investment in the DSL.
    
        The current study supports our ongoing efforts and plans to port other physical parametrizations to Python with GT4Py. However, we note that GT4Py has been originally devised to express the computational motifs of dynamical cores based on grid-point methods, so not all patterns found in the parametrizations are natively supported by the DSL. \review{In this respect, the main limitations of the DSL pertain to data dimensions, single column abstractions, and vertical reductions.} These \review{deficiencies} may be addressed by new features added to GT4Py or by resorting to other Python libraries to generate fast machine code.
        
        % For instance, absolute indexing and off-center writing are not implemented, so workarounds are needed to update the surface layer from each vertical level and modify two consecutive vertical layers in conjunction. 
        % possibly recycling the prototype infrastructure code presented in this manuscript.
    
    %\biblio
\end{document}
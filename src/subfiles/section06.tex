\documentclass[main.tex]{subfiles}

\begin{document}
    \justifying

    \section{Conclusions}
    \label{section:conclusions} 

    The CLOUDSC and CLOUDSC2 cloud microphysics schemes from the IFS physics suite have served as demonstrators to showcase the benefits deriving from a high-level domain-specific approach to physical parametrizations for NWP. We presented two novel Python implementations based on the GT4Py framework, where the scientific code is insulated from hardware-specific specializations. The result is a hardware-agnostic user application with enhanced readability and maintainability, which can run in a robust manner on a wide spectrum of compute architectures. The latter point is of primary interest in the light of the current HPC technology landscape, where general-purpose CPUs are increasingly complemented by domain-specific architectures (DSAs) such as GPUs, Tensor Processor Units (TPUs), Field Programmable Gate Arrays (FPGAs), and Application-Specific Integrated Circuits (ASICS).

    In both CLOUDSC-GT4Py and CLOUDSC2-GT4Py, the stencil kernels are encapsulated within model components sharing a minimal and clear interface. By avoiding any assumption on the host model, the interface is aimed to devise inter-operable and plug-and-play physical packages, which can be transferred more easily between different modeling systems with virtually no performance penalty.

    We carried out a comprehensive study to assess the portability of the Python codes across three top-class supercomputers, differing for the manufacturer, the node architecture, the software stack and the compiler suites. We showed that the GPU performance of GT4Py codes are comparable to optimized Fortran OpenACC implementations and superior to the source-to-source translation tool Loki. However, CLOUDSC-GT4Py and CLOUDSC2-GT4Py cannot yet attain the same performance as native implementations, both on CPU (Fortran) and GPU (CUDA/HIP).

    On the one hand, we are not particularly concerned about the overall performance of the CPU backends of GT4Py. The results shown in this paper help create clear evidence that weather and climate model codes can execute significantly faster on GPUs \citep{fuhrer18}, and the number of world-wide HPC systems offering some sort of accelerators is steadily increasing\footnote{In the 62\textsuperscript{nd} edition of the TOP500 list published in November 2023, 186 out of the 500 most powerful supercomputers in the world use graphics accelerator technology (\url{https://www.top500.org/lists/top500/2023/11/highs/}).}. Therefore, we envision that CPUs will be increasingly relegated to non-time-critical tasks in the future.

    On the other hand, we recognize that GPU performance are of utter importance in view of a future adoption of GT4Py in an operational context. It should be mentioned, however, that the CUDA and HIP implementations of CLOUDSC has been written from scratch by GPU experts, and the final version of the code is the result of a long iterative hand-optimization process, which is hardly scalable to the full model. On the contrary, we believe that the GPU porting of a full-fledge model via a ground-up re-writing using a DSL is not only possible, but also more sustainable and cost-effective than a directive-based approach. Indeed, DSLs enable a separation of concerns between domain scientists and computer experts, so that both can better exploit the respective field of expertise and thus boost their productivity. Notwithstanding, we stress that the development and maintenance of the DSL toolchain with respect to emerging computational patterns and heterogeneous compute platforms is complex and does not come for free. However, provided that the design of the toolchain is driven by a close synergy between domain scientists and computer experts, the advantages for all downstream applications are likely to offset the investment in the DSL.

    Finally, we remind that GT4Py has been originally devised to express the computational motifs ubiquitous in dynamical cores. It is then not surprising that some patterns found in the CLOUDSC and CLOUDSC2 microphysics codes are not natively supported by the DSL. %For instance, absolute indexing and off-center writing are not implemented, so workarounds are needed to update the surface layer from each vertical level and modify two consecutive vertical layers in conjunction.
    It is not clear yet whether GT4Py will be the most appropriate tool to port all physical packages to graphics accelerators. We plan to conduct more feasibility and portability studies targeting diverse physical parametrizations, possibly recycling the prototype infrastructure code presented in this manuscript.

    \biblio
\end{document}